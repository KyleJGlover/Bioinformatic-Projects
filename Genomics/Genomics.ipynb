{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with high-quality reference genomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from IPython.core.display import Image\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import cm\n",
    "from Bio import SeqIO\n",
    "from Bio.Graphics import BasicChromosome\n",
    "\n",
    "# Define the name of the genome file\n",
    "genome_name = 'PlasmoDB-13.0_Pfalciparum3D7_Genome.fasta'\n",
    "\n",
    "# Read the genome sequences from the file\n",
    "recs = SeqIO.parse(genome_name, 'fasta')\n",
    "chroms = {}\n",
    "\n",
    "# Iterate over the genome sequences and print their descriptions\n",
    "for rec in recs:\n",
    "    print(rec.description)\n",
    "\n",
    "# +\n",
    "# Import SeqUtils from Biopython\n",
    "from Bio import SeqUtils\n",
    "\n",
    "# Initialize dictionaries to store chromosome sizes and GC content\n",
    "chrom_sizes = {}\n",
    "chrom_GC = {}\n",
    "\n",
    "# Read the genome sequences again\n",
    "recs = SeqIO.parse(genome_name, 'fasta')\n",
    "block_size = 50000\n",
    "min_GC = 100.0\n",
    "max_GC = 0.0\n",
    "\n",
    "# Iterate over the genome sequences\n",
    "for rec in recs:\n",
    "    # Check if the sequence represents a chromosome\n",
    "    if rec.description.find('SO=chromosome') == -1:\n",
    "        continue\n",
    "    # Extract chromosome number from the description\n",
    "    chrom = int(rec.description.split('_')[1])\n",
    "    chrom_GC[chrom] = []\n",
    "    size = len(rec.seq)\n",
    "    chrom_sizes[chrom] = size\n",
    "    num_blocks = size // block_size + 1\n",
    "    \n",
    "    # Iterate over the sequence in blocks of defined size\n",
    "    for block in range(num_blocks):\n",
    "        start = block_size * block\n",
    "        if block == num_blocks - 1:\n",
    "            end = size\n",
    "        else:\n",
    "            end = block_size + start + 1\n",
    "        block_seq = rec.seq[start:end]\n",
    "        # Calculate the GC content of the block\n",
    "        block_GC = SeqUtils.GC(block_seq)\n",
    "        if block_GC < min_GC:\n",
    "            min_GC = block_GC\n",
    "        if block_GC > max_GC:\n",
    "            max_GC = block_GC\n",
    "        chrom_GC[chrom].append(block_GC)\n",
    "\n",
    "# Print the minimum and maximum GC content found in the genome\n",
    "print(min_GC, max_GC)\n",
    "\n",
    "# +\n",
    "# Extract the chromosome numbers and sort them\n",
    "chroms = list(chrom_sizes.keys())\n",
    "chroms.sort()\n",
    "\n",
    "# Find the size of the largest chromosome\n",
    "biggest_chrom = max(chrom_sizes.values())\n",
    "\n",
    "# Initialize variables for color-coding the chromosomes based on GC content\n",
    "my_genome = BasicChromosome.Organism(output_format=\"png\")\n",
    "my_genome.page_size = (29.7*cm, 21*cm)  # Set the page size\n",
    "\n",
    "telomere_length = 10  # Define the length of telomeres\n",
    "\n",
    "bottom_GC = 17.5  # Define the lower bound for GC content color\n",
    "top_GC = 22.0  # Define the upper bound for GC content color\n",
    "\n",
    "# Iterate over the chromosomes to create chromosome representations\n",
    "for chrom in chroms:\n",
    "    chrom_size = chrom_sizes[chrom]\n",
    "    chrom_representation = BasicChromosome.Chromosome('Cr %d' % chrom)\n",
    "    chrom_representation.scale_num = biggest_chrom\n",
    "\n",
    "    tel = BasicChromosome.TelomereSegment()\n",
    "    tel.scale = telomere_length\n",
    "    chrom_representation.add(tel)\n",
    "\n",
    "    num_blocks = len(chrom_GC[chrom])\n",
    "    # Iterate over the GC content blocks and color-code them accordingly\n",
    "    for block, gc in enumerate(chrom_GC[chrom]):\n",
    "        my_GC = chrom_GC[chrom][block]\n",
    "        body = BasicChromosome.ChromosomeSegment()\n",
    "        if my_GC > top_GC:\n",
    "            body.fill_color = colors.Color(1, 0, 0)  # Red color for high GC content\n",
    "        elif my_GC < bottom_GC:\n",
    "            body.fill_color = colors.Color(1, 1, 0)  # Yellow color for low GC content\n",
    "        else:\n",
    "            my_color = (my_GC - bottom_GC) / (top_GC - bottom_GC)\n",
    "            body.fill_color = colors.Color(my_color, my_color, 1)\n",
    "        if block < num_blocks - 1:\n",
    "            body.scale = block_size\n",
    "        else:\n",
    "            body.scale = chrom_size % block_size\n",
    "        chrom_representation.add(body)\n",
    "\n",
    "    tel = BasicChromosome.TelomereSegment(inverted=True)\n",
    "    tel.scale = telomere_length\n",
    "    chrom_representation.add(tel)\n",
    "\n",
    "    # Add the chromosome representation to the genome\n",
    "    my_genome.add(chrom_representation)\n",
    "\n",
    "# Draw the chromosome representations and save as an image\n",
    "my_genome.draw(\"falciparum.png\", \"Plasmodium falciparum\")\n",
    "\n",
    "# Display the generated image\n",
    "Image(\"falciparum.png\")\n",
    "# -"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "from Bio import ExPASy, SwissProt\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Define the UniProt server URL\n",
    "server = 'http://www.uniprot.org/uniprot'\n",
    "\n",
    "# Function to send a request to the UniProt server\n",
    "def do_request(server, ID='', **kwargs):\n",
    "    params = ''\n",
    "    req = requests.get('%s/%s%s' % (server, ID, params), params=kwargs)\n",
    "    if not req.ok:\n",
    "        req.raise_for_status()\n",
    "    return req\n",
    "\n",
    "# Send a request to the UniProt server to fetch information about the human gene 'p53'\n",
    "# We are retrieving limited columns for 50 entries related to the gene 'p53' that have been reviewed\n",
    "# Note: We might revisit this for KEGG data in the future\n",
    "req = do_request(server, query='gene:p53 AND reviewed:yes', format='tab',\n",
    "                 columns='id,entry name,length,organism,organism-id,database(PDB),database(HGNC)',\n",
    "                 limit='50')\n",
    "\n",
    "# Convert the response to a DataFrame using pandas\n",
    "uniprot_list = pd.read_table(io.StringIO(req.text))\n",
    "uniprot_list.rename(columns={'Organism ID': 'ID'}, inplace=True)\n",
    "\n",
    "# Get the UniProt entry for the human gene 'p53'\n",
    "p53_human = uniprot_list[\n",
    "    (uniprot_list.ID == 9606) &\n",
    "    (uniprot_list['Entry name'].str.contains('P53'))]['Entry'].iloc[0]\n",
    "\n",
    "# Get the UniProt record for the specified entry (p53_human) using ExPASy\n",
    "handle = ExPASy.get_sprot_raw(p53_human)\n",
    "sp_rec = SwissProt.read(handle)\n",
    "\n",
    "# Print some information about the UniProt record\n",
    "print(sp_rec.entry_name, sp_rec.sequence_length, sp_rec.gene_name)\n",
    "print(sp_rec.description)\n",
    "print(sp_rec.organism, sp_rec.seqinfo)\n",
    "print(sp_rec.sequence)\n",
    "\n",
    "# Print comments and keywords associated with the UniProt record\n",
    "print(sp_rec.comments)\n",
    "print(sp_rec.keywords)\n",
    "\n",
    "# Get a list of unique features in the UniProt record and print them\n",
    "done_features = set()\n",
    "print('Total features:', len(sp_rec.features))\n",
    "for feature in sp_rec.features:\n",
    "    if feature in done_features:\n",
    "        continue\n",
    "    else:\n",
    "        done_features.add(feature)\n",
    "        print(feature)\n",
    "\n",
    "# Get a list of cross-references in the UniProt record, grouped by source, and print them\n",
    "per_source = defaultdict(list)\n",
    "for xref in sp_rec.cross_references:\n",
    "    source = xref[0]\n",
    "    per_source[source].append(xref[1:])\n",
    "print(per_source.keys())\n",
    "\n",
    "# Get a list of unique Gene Ontology (GO) annotations in the UniProt record and print them\n",
    "done_GOs = set()\n",
    "print('Annotation SOURCES:', len(per_source['GO']))\n",
    "for annot in per_source['GO']:\n",
    "    if annot[1][0] in done_GOs:\n",
    "        continue\n",
    "    else:\n",
    "        done_GOs.add(annot[1][0])\n",
    "        print(annot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from collections import defaultdict\n",
    "import gffutils\n",
    "import sqlite3\n",
    "\n",
    "# Define the URL for downloading the GFF file and the database file\n",
    "gff_url = 'https://vectorbase.org/common/downloads/release-55/AgambiaePEST/gff/data/VectorBase-55_AgambiaePEST.gff'\n",
    "gff_file = 'gambiae.gff'\n",
    "db_file = 'ag.db'\n",
    "\n",
    "# Create or connect to the database using gffutils\n",
    "try:\n",
    "    db = gffutils.create_db(gff_file + '.gz', db_file)\n",
    "except sqlite3.OperationalError:\n",
    "    db = gffutils.FeatureDB(db_file)\n",
    "\n",
    "# Print the list of feature types in the GFF file\n",
    "print(list(db.featuretypes()))\n",
    "\n",
    "# Count the number of features for each feature type in the database\n",
    "for feat_type in db.featuretypes():\n",
    "    print(feat_type, db.count_features_of_type(feat_type))\n",
    "\n",
    "# Get the unique sequence IDs present in the database\n",
    "seqids = set()\n",
    "for e in db.all_features():\n",
    "    seqids.add(e.seqid)\n",
    "for seqid in seqids:\n",
    "    print(seqid)\n",
    "\n",
    "# Initialize defaultdicts to count the number of mRNAs and exons for each gene\n",
    "num_mRNAs = defaultdict(int)\n",
    "num_exons = defaultdict(int)\n",
    "max_exons = 0\n",
    "max_span = 0\n",
    "\n",
    "# Loop through each sequence ID and analyze the genes in the region\n",
    "for seqid in seqids:\n",
    "    cnt = 0\n",
    "    for gene in db.region(seqid=seqid, featuretype='protein_coding_gene'):\n",
    "        cnt += 1\n",
    "        # Calculate the span of the gene (difference between start and end positions)\n",
    "        span = abs(gene.start - gene.end) # strand\n",
    "        if span > max_span:\n",
    "            max_span = span\n",
    "            max_span_gene = gene\n",
    "        # Get the mRNA features for the gene and count the number of mRNAs for each gene\n",
    "        my_mRNAs = list(db.children(gene, featuretype='mRNA'))\n",
    "        num_mRNAs[len(my_mRNAs)] += 1\n",
    "        # Determine if the gene has exons or not (exon_check will contain either gene or mRNA features)\n",
    "        if len(my_mRNAs) == 0:\n",
    "            exon_check = [gene]\n",
    "        else:\n",
    "            exon_check = my_mRNAs\n",
    "        # Get the exon features and count the number of exons for each gene/mRNA\n",
    "        for check in exon_check:\n",
    "            my_exons = list(db.children(check, featuretype='exon'))\n",
    "            num_exons[len(my_exons)] += 1\n",
    "            # Track the gene with the maximum number of exons\n",
    "            if len(my_exons) > max_exons:\n",
    "                max_exons = len(my_exons)\n",
    "                max_exons_gene = gene\n",
    "    print(f'seqid {seqid}, number of genes {cnt}')\n",
    "\n",
    "# Print the gene with the maximum number of exons and its count\n",
    "print('Max number of exons: %s (%d)' % (max_exons_gene.id, max_exons))\n",
    "\n",
    "# Print the gene with the maximum span and its span value\n",
    "print('Max span: %s (%d)' % (max_span_gene.id, max_span))\n",
    "\n",
    "# Print the counts of mRNAs and exons for each gene\n",
    "print(num_mRNAs)\n",
    "print(num_exons)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Low-quality reference genomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO, SeqUtils\n",
    "\n",
    "# Download genome sequences of Anopheles gambiae and Aedes atroparvus\n",
    "gambiae_name = 'gambiae.fa.gz'\n",
    "atroparvus_name = 'atroparvus.fa.gz'\n",
    "\n",
    "# Display descriptions of the sequences in the Anopheles gambiae genome\n",
    "recs = SeqIO.parse(gzip.open(gambiae_name, 'rt', encoding='utf-8'), 'fasta')\n",
    "for rec in recs:\n",
    "    print(rec.description)\n",
    "\n",
    "# Calculate the fraction of Ns (ambiguous nucleotides) in each contig of Anopheles gambiae genome\n",
    "recs = SeqIO.parse(gzip.open(gambiae_name, 'rt', encoding='utf-8'), 'fasta')\n",
    "chrom_Ns = {}\n",
    "chrom_sizes = {}\n",
    "for rec in recs:\n",
    "    # Skip supercontigs in the genome\n",
    "    if rec.description.find('supercontig') > -1:\n",
    "        continue\n",
    "    print(rec.description, rec.id, rec)\n",
    "    chrom = rec.id.split('_')[1]\n",
    "    if chrom in ['UNKN']:\n",
    "        continue\n",
    "    chrom_Ns[chrom] = []\n",
    "    on_N = False\n",
    "    curr_size = 0\n",
    "    for pos, nuc in enumerate(rec.seq):\n",
    "        if nuc in ['N', 'n']:\n",
    "            curr_size += 1\n",
    "            on_N = True\n",
    "        else:\n",
    "            if on_N:\n",
    "                chrom_Ns[chrom].append(curr_size)\n",
    "                curr_size = 0\n",
    "            on_N = False\n",
    "    if on_N:\n",
    "        chrom_Ns[chrom].append(curr_size)\n",
    "    chrom_sizes[chrom] = len(rec.seq)\n",
    "\n",
    "# Display the fraction of Ns, number of Ns, and the maximum number of consecutive Ns for each contig\n",
    "for chrom, Ns in chrom_Ns.items():\n",
    "    size = chrom_sizes[chrom]\n",
    "    if len(Ns) > 0:\n",
    "        max_Ns = max(Ns)\n",
    "    else:\n",
    "        max_Ns = 'NA'\n",
    "    print(f'{chrom} ({size}): %Ns ({round(100 * sum(Ns) / size, 1)}), num Ns: {len(Ns)}, max N: {max_Ns}')\n",
    "\n",
    "# Calculate statistics for the sizes of sequences in the Aedes atroparvus genome\n",
    "recs = SeqIO.parse(gzip.open(atroparvus_name, 'rt', encoding='utf-8'), 'fasta')\n",
    "sizes = []\n",
    "size_N = []\n",
    "for rec in recs:\n",
    "    size = len(rec.seq)\n",
    "    sizes.append(size)\n",
    "    count_N = 0\n",
    "    for nuc in rec.seq:\n",
    "        if nuc in ['n', 'N']:\n",
    "            count_N += 1\n",
    "    size_N.append((size, count_N / size))\n",
    "\n",
    "# Display statistics for sequence sizes in the Aedes atroparvus genome\n",
    "print(len(sizes), np.median(sizes), np.mean(sizes), max(sizes), min(sizes),\n",
    "      np.percentile(sizes, 10), np.percentile(sizes, 90))\n",
    "\n",
    "# Create a plot showing the fraction of Ns in contigs of different sizes in the Aedes atroparvus genome\n",
    "small_split = 4800\n",
    "large_split = 540000\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 9), dpi=300, squeeze=False, sharey=True)\n",
    "xs, ys = zip(*[(x, 100 * y) for x, y in size_N if x <= small_split])\n",
    "axs[0, 0].plot(xs, ys, '.')\n",
    "xs, ys = zip(*[(x, 100 * y) for x, y in size_N if x > small_split and x <= large_split])\n",
    "axs[0, 1].plot(xs, ys, '.')\n",
    "axs[0, 1].set_xlim(small_split, large_split)\n",
    "xs, ys = zip(*[(x, 100 * y) for x, y in size_N if x > large_split])\n",
    "axs[0, 2].plot(xs, ys, '.')\n",
    "axs[0, 0].set_ylabel('Fraction of Ns', fontsize=12)\n",
    "axs[0, 1].set_xlabel('Contig size', fontsize=12)\n",
    "fig.suptitle('Fraction of Ns per contig size', fontsize=26)\n",
    "fig.savefig('frac.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding orthologues with the Ensembl REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "ensembl_server = 'http://rest.ensembl.org'\n",
    "\n",
    "def do_request(server, service, *args, **kwargs):\n",
    "    # Prepare URL parameters for the request\n",
    "    url_params = ''\n",
    "    for a in args:\n",
    "        if a is not None:\n",
    "            url_params += '/' + a\n",
    "    # Send a GET request to the specified service with the provided parameters and headers\n",
    "    req = requests.get('%s/%s%s' % (server, service, url_params),\n",
    "                       params=kwargs,\n",
    "                       headers={'Content-Type': 'application/json'})\n",
    " \n",
    "    # Check if the request was successful; if not, raise an exception\n",
    "    if not req.ok:\n",
    "        req.raise_for_status()\n",
    "    return req.json()\n",
    "\n",
    "# Get information about available species from Ensembl\n",
    "answer = do_request(ensembl_server, 'info/species')\n",
    "for i, sp in enumerate(answer['species']):\n",
    "    print(i, sp['name'])\n",
    "\n",
    "# Get information about external databases for Homo sapiens from Ensembl\n",
    "ext_dbs = do_request(ensembl_server, 'info/external_dbs', 'homo_sapiens', filter='HGNC%')\n",
    "print(ext_dbs)\n",
    "\n",
    "# Lookup information about a gene with the symbol 'LCT' in Homo sapiens\n",
    "answer = do_request(ensembl_server, 'lookup/symbol', 'homo_sapiens', 'LCT')\n",
    "print(answer)\n",
    "lct_id = answer['id']\n",
    "\n",
    "# Get the DNA sequence of the gene with the specified Ensembl ID\n",
    "lct_seq = do_request(ensembl_server, 'sequence/id', lct_id)\n",
    "print(lct_seq)\n",
    "\n",
    "# Get cross-references (Xrefs) for the gene with the specified Ensembl ID\n",
    "lct_xrefs = do_request(ensembl_server, 'xrefs/id', lct_id)\n",
    "for xref in lct_xrefs:\n",
    "    print(xref['db_display_name'])\n",
    "    print(xref)\n",
    "\n",
    "# Get cross-references (Xrefs) for the gene with the specified Ensembl ID and external database 'GO'\n",
    "refs = do_request(ensembl_server, 'xrefs/id', lct_id, external_db='GO', all_levels='1')\n",
    "print(lct_id, refs)\n",
    "\n",
    "# Get homology information for the gene with the specified Ensembl ID, type='orthologues', and no sequence data\n",
    "hom_response = do_request(ensembl_server, 'homology/id', lct_id, type='orthologues', sequence='none')\n",
    "# Retrieve the list of homologies and print information for homologous genes\n",
    "homologies = hom_response['data'][0]['homologies']\n",
    "for homology in homologies:\n",
    "    print(homology['target']['species'])\n",
    "    if homology['target']['species'] != 'equus_caballus':\n",
    "        continue\n",
    "    print(homology)\n",
    "    print(homology['taxonomy_level'])\n",
    "    horse_id = homology['target']['id']\n",
    "\n",
    "# Get information about the homologous gene in Equus caballus (horse) using its Ensembl ID\n",
    "horse_req = do_request(ensembl_server, 'lookup/id', horse_id)\n",
    "print(horse_req)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "ensembl_server = 'http://rest.ensembl.org'\n",
    "\n",
    "def do_request(server, service, *args, **kwargs):\n",
    "    # Prepare URL parameters for the request\n",
    "    params = ''\n",
    "    for a in args:\n",
    "        if a is not None:\n",
    "            params += '/' + a\n",
    "    # Send a GET request to the specified service with the provided parameters and headers\n",
    "    req = requests.get('%s/%s%s' % (server, service, params),\n",
    "                       params=kwargs,\n",
    "                       headers={'Content-Type': 'application/json'})\n",
    " \n",
    "    # Check if the request was successful; if not, raise an exception\n",
    "    if not req.ok:\n",
    "        req.raise_for_status()\n",
    "    return req.json()\n",
    "\n",
    "\n",
    "# Specify the Ensembl ID for the gene of interest (LCT)\n",
    "lct_id = 'ENSG00000115850'\n",
    "\n",
    "# Get cross-references (Xrefs) for the gene with the specified Ensembl ID and external database 'GO' (Gene Ontology)\n",
    "refs = do_request(ensembl_server, 'xrefs/id', lct_id, external_db='GO', all_levels='1')\n",
    "print(len(refs))\n",
    "print(refs[0].keys())\n",
    "for ref in refs:\n",
    "    # Extract the Gene Ontology (GO) ID and retrieve ontology information for that ID\n",
    "    go_id = ref['primary_id']\n",
    "    details = do_request(ensembl_server, 'ontology/id', go_id)\n",
    "    print('%s %s %s' % (go_id,  details['namespace'], ref['description']))\n",
    "    print('%s\\n' % details['definition'])\n",
    "\n",
    "# Example: Retrieve information for a specific GO ID (GO:0000016)\n",
    "go_id = 'GO:0000016'\n",
    "my_data = do_request(ensembl_server, 'ontology/id', go_id)\n",
    "for k, v in my_data.items():\n",
    "    if k == 'parents':\n",
    "        for parent in v:\n",
    "            print(parent)\n",
    "            parent_id = parent['accession']\n",
    "    else:\n",
    "        print('%s: %s' % (k, str(v)))\n",
    "print()\n",
    "\n",
    "# Retrieve information for the parent term of the GO term (GO:0000016)\n",
    "parent_data = do_request(ensembl_server, 'ontology/id', parent_id)\n",
    "print(parent_id, len(parent_data['children']))\n",
    "\n",
    "# Retrieve ancestor terms (chart) for the GO term (GO:0000016)\n",
    "refs = do_request(ensembl_server, 'ontology/ancestors/chart', go_id)\n",
    "for go, entry in refs.items():\n",
    "    print(go)\n",
    "    term = entry['term']\n",
    "    print('%s %s' % (term['name'], term['definition']))\n",
    "    is_a = entry.get('is_a', [])\n",
    "    print('\\t is a: %s\\n' % ', '.join([x['accession'] for x in is_a]))\n",
    "\n",
    "# Function to get parent terms and node data for a given GO ID\n",
    "def get_upper(go_id):\n",
    "    parents = {}\n",
    "    node_data = {}\n",
    "    refs = do_request(ensembl_server, 'ontology/ancestors/chart', go_id)\n",
    "    for ref, entry in refs.items():\n",
    "        my_data = do_request(ensembl_server, 'ontology/id', ref)\n",
    "        node_data[ref] = {'name': entry['term']['name'], 'children': my_data['children']}\n",
    "        try:\n",
    "            parents[ref] = [x['accession'] for x in entry['is_a']]\n",
    "        except KeyError:\n",
    "            pass  # Top of hierarchy\n",
    "    return parents, node_data\n",
    "\n",
    "# Get parent terms and node data for the GO term (GO:0000016)\n",
    "parents, node_data = get_upper(go_id)\n",
    "\n",
    "# Create a graph to visualize the ontology tree\n",
    "g = pgv.AGraph(directed=True)\n",
    "for ofs, ofs_parents in parents.items():\n",
    "    ofs_text = '%s\\n(%s)' % (node_data[ofs]['name'].replace(', ', '\\n'), ofs)\n",
    "    for parent in ofs_parents:\n",
    "        parent_text = '%s\\n(%s)' % (node_data[parent]['name'].replace(', ', '\\n'), parent)\n",
    "        children = node_data[parent]['children']\n",
    "        if len(children) < 3:\n",
    "            for child in children:\n",
    "                if child['accession'] in node_data:\n",
    "                    continue\n",
    "                g.add_edge(parent_text, child['accession'])\n",
    "        else:\n",
    "            g.add_edge(parent_text, '...%d...' % (len(children) - 1))\n",
    "        g.add_edge(parent_text, ofs_text)\n",
    "\n",
    "# Set graph attributes and layout for visualization\n",
    "g.graph_attr['label']='Ontology tree for Lactase activity'\n",
    "g.node_attr['shape']='rectangle'\n",
    "g.layout(prog='dot')\n",
    "\n",
    "# Save the ontology tree as an image\n",
    "g.draw('graph.png')\n",
    "\n",
    "# Print the GO ID and information for the descendants of the GO term (GO:0000016)\n",
    "print(go_id)\n",
    "refs = do_request(ensembl_server, 'ontology/descendants', go_id)\n",
    "for go in refs:\n",
    "    print(go['accession'], go['name'], go['definition'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
