{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + [markdown] jupyter={\"outputs_hidden\": false}\n",
    "# http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "# !wget http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
    "# !wget http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "# -\n",
    "\n",
    "# ## With scikit-learn\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "\n",
    "# Import Libaries\n",
    "import numpy as np # Import the library from numpy package\n",
    "import pandas as pd # Import the library from pandas package\n",
    "from sklearn.ensemble import RandomForestClassifier # Import the classifier\n",
    "from sklearn.model_selection import train_test_split # Import the classifier\n",
    "from sklearn.tree import export_graphviz # Export the graphviz package\n",
    "\n",
    "# Import necessary libraries\n",
    "f = open('breast-cancer-wisconsin.data')  # Open input file\n",
    "w = open('clean.data', 'w')  # Open output file for writing\n",
    "\n",
    "# Clean the data by removing lines with missing values and write it to 'clean.data'\n",
    "for line in f:\n",
    "    if line.find('?') > -1:  # Skip lines with missing values indicated by '?'\n",
    "        continue\n",
    "    w.write(line)\n",
    "\n",
    "f.close()  # Close input file\n",
    "w.close()  # Close output file\n",
    "\n",
    "column_names = [\n",
    "    'sample_id', 'clump_thickness', 'uniformity_cell_size',\n",
    "    'uniformity_cell shape', 'marginal_adhesion',\n",
    "    'single_epithelial_cell_size', 'bare_nuclei',\n",
    "    'bland_chromatin', 'normal_nucleoli', 'mitoses',\n",
    "    'class'\n",
    "]\n",
    "\n",
    "# Read the cleaned data from 'clean.data' and assign column names\n",
    "samples = pd.read_csv('clean.data', header=None, names=column_names, index_col=0)\n",
    "samples\n",
    "\n",
    "trainning_input = samples.iloc[:,:-1]  # Extract input features\n",
    "target = samples.iloc[:,-1]  # Extract target variable\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=3, n_estimators=200)  # Create a random forest classifier\n",
    "\n",
    "clf.fit(trainning_input, target)  # Train the classifier on the training data\n",
    "\n",
    "# Calculate feature importances and sort them in descending order\n",
    "importances = pd.Series(\n",
    "    clf.feature_importances_ * 100,\n",
    "    index=trainning_input.columns).sort_values(ascending=False)\n",
    "importances\n",
    "\n",
    "# Calculate the accuracy of the classifier on the training data\n",
    "accuracy = 100 * clf.score(trainning_input, target)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy)\n",
    "\n",
    "# Perform multiple train-test splits and evaluate the classifier on each split\n",
    "for test_size in [0.01, 0.1, 0.2, 0.5, 0.8, 0.9, 0.99]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        trainning_input, target, test_size=test_size)\n",
    "    tclf = RandomForestClassifier(max_depth=3)  # Create a new random forest classifier\n",
    "    tclf.fit(X_train, y_train)  # Train the classifier on the training data\n",
    "    score = tclf.score(X_test, y_test)  # Calculate the accuracy on the test data\n",
    "    print(f'{1 - test_size:.1%} {score:.2%}')  # Print the test size and accuracy\n",
    "\n",
    "# Random number generator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pygenomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "from genomics.popgen.pca import plot\n",
    "# -\n",
    "\n",
    "# ## Meta-data load\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "f = open('relationships_w_pops_041510.txt')\n",
    "ind_pop = {}\n",
    "f.readline()  # header\n",
    "for l in f:\n",
    "    toks = l.rstrip().split('\\t')\n",
    "    fam_id = toks[0]\n",
    "    ind_id = toks[1]\n",
    "    pop = toks[-1]\n",
    "    ind_pop['/'.join([fam_id, ind_id])] = pop\n",
    "f.close()\n",
    "# -\n",
    "\n",
    "# ## With scikit-learn\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "f = open('hapmap10_auto_noofs_ld_12.ped')\n",
    "ninds = 0\n",
    "ind_order = []\n",
    "for line in f:\n",
    "    ninds += 1\n",
    "    toks = line[:100].replace(' ', '\\t').split('\\t') #  for speed\n",
    "    fam_id = toks[0]\n",
    "    ind_id = toks[1]\n",
    "    ind_order.append('%s/%s' % (fam_id, ind_id))\n",
    "nsnps = (len(line.replace(' ', '\\t').split('\\t')) - 6) // 2\n",
    "f.close()\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "pca_array = np.empty((ninds, nsnps), dtype=int)\n",
    "print(pca_array.shape)\n",
    "f = open('hapmap10_auto_noofs_ld_12.ped')\n",
    "for ind, line in enumerate(f):\n",
    "    snps = line.replace(' ', '\\t').split('\\t')[6:]\n",
    "    for pos in range(len(snps) // 2):\n",
    "        try:\n",
    "            a1 = int(snps[2 * pos])\n",
    "            a2 = int(snps[2 * pos + 1])\n",
    "            my_code = a1 + a2 - 2\n",
    "        except ValueError:\n",
    "            my_code = -1  # Assigning -1 for non-numeric SNPs\n",
    "        pca_array[ind, pos] = my_code\n",
    "f.close()\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "my_pca = PCA(n_components=8)\n",
    "my_pca.fit(pca_array)\n",
    "trans = my_pca.transform(pca_array)\n",
    "#Memory required\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "sc_ind_comp = {}\n",
    "for i, ind_pca in enumerate(trans):\n",
    "    sc_ind_comp[ind_order[i]] = ind_pca\n",
    "plot.render_pca_eight(sc_ind_comp, cluster=ind_pop)\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "# + [markdown] jupyter={\"outputs_hidden\": false}\n",
    "# http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "# !wget http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
    "# !wget http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "# -\n",
    "\n",
    "# ## With scikit-learn\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "f = open('breast-cancer-wisconsin.data')\n",
    "w = open('clean.data', 'w')\n",
    "for line in f:\n",
    "    if line.find('?') > -1:\n",
    "        continue\n",
    "    w.write(line)\n",
    "f.close()\n",
    "w.close()\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "column_names = [\n",
    "    'sample_id', 'clump_thickness', 'uniformity_cell_size',\n",
    "    'uniformity_cell shape', 'marginal_adhesion',\n",
    "    'single_epithelial_cell_size', 'bare_nuclei',\n",
    "    'bland_chromatin', 'normal_nucleoli', 'mitoses',\n",
    "    'class'\n",
    "]\n",
    "samples = pd.read_csv('clean.data', header=None, names=column_names, index_col=0)\n",
    "samples\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "training_input = samples.iloc[:,:-1]\n",
    "target = samples.iloc[:,-1].apply(lambda x: 0 if x == 2 else 1)\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "clf.fit(training_input, target)\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "importances = pd.Series(\n",
    "    clf.feature_importances_ * 100,\n",
    "    index=training_input.columns).sort_values(ascending=False)\n",
    "importances\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "100 * clf.score(training_input, target)\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "fig, ax = plt.subplots(1, dpi=300)\n",
    "tree.plot_tree(clf,ax=ax, feature_names=training_input.columns, class_names=['Benign', 'Malignant'])\n",
    "# -"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from genomics.popgen.pca import plot\n",
    "# -\n",
    "\n",
    "# ## Meta-data load\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "f = open('relationships_w_pops_041510.txt')\n",
    "ind_pop = {}\n",
    "f.readline()  # header\n",
    "for l in f:\n",
    "    toks = l.rstrip().split('\\t')\n",
    "    fam_id = toks[0]\n",
    "    ind_id = toks[1]\n",
    "    pop = toks[-1]\n",
    "    ind_pop['/'.join([fam_id, ind_id])] = pop\n",
    "f.close()\n",
    "# -\n",
    "\n",
    "# ## With scikit-learn\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "f = open('hapmap10_auto_noofs_ld_12.ped')\n",
    "ninds = 0\n",
    "ind_order = []\n",
    "for line in f:\n",
    "    ninds += 1\n",
    "    toks = line[:100].replace(' ', '\\t').split('\\t') #  for speed\n",
    "    fam_id = toks[0]\n",
    "    ind_id = toks[1]\n",
    "    ind_order.append('%s/%s' % (fam_id, ind_id))\n",
    "nsnps = (len(line.replace(' ', '\\t').split('\\t')) - 6) // 2\n",
    "print (nsnps)\n",
    "f.close()\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "all_array = np.empty((ninds, nsnps), dtype=int)\n",
    "f = open('../Chapter06/hapmap10_auto_noofs_ld_12.ped')\n",
    "for ind, line in enumerate(f):\n",
    "    snps = line.replace(' ', '\\t').split('\\t')[6:]\n",
    "    for pos in range(len(snps) // 2):\n",
    "        a1 = int(snps[2 * pos])\n",
    "        a2 = int(snps[2 * pos])\n",
    "        my_code = a1 + a2 - 2\n",
    "        all_array[ind, pos] = my_code\n",
    "f.close()\n",
    "#slow\n",
    "# -\n",
    "\n",
    "predict_case = all_array[-1, :]\n",
    "pca_array = all_array[:-1,:]\n",
    "\n",
    "last_ind = ind_order[-1]\n",
    "last_ind, ind_pop[last_ind]\n",
    "\n",
    "my_pca = PCA(n_components=2)\n",
    "my_pca.fit(pca_array)\n",
    "trans = my_pca.transform(pca_array)\n",
    "\n",
    "sc_ind_comp = {}\n",
    "for i, ind_pca in enumerate(trans):\n",
    "    sc_ind_comp[ind_order[i]] = ind_pca\n",
    "plot.render_pca(sc_ind_comp, cluster=ind_pop)\n",
    "\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "def plot_kmeans_pca(trans, kmeans):\n",
    "    x_min, x_max = trans[:, 0].min() - 1, trans[:, 0].max() + 1\n",
    "    y_min, y_max = trans[:, 1].min() - 1, trans[:, 1].max() + 1\n",
    "    mesh_x, mesh_y = np.meshgrid(np.arange(x_min, x_max, 0.5), np.arange(y_min, y_max, 0.5))\n",
    "\n",
    "    k_surface = kmeans.predict(np.c_[mesh_x.ravel(), mesh_y.ravel()]).reshape(mesh_x.shape)\n",
    "    fig, ax = plt.subplots(1,1, dpi=300)\n",
    "    ax.imshow(\n",
    "        k_surface, origin=\"lower\", cmap=plt.cm.Pastel1,\n",
    "        extent=(mesh_x.min(), mesh_x.max(), mesh_y.min(), mesh_y.max()),\n",
    "    )\n",
    "\n",
    "    ax.plot(trans[:, 0], trans[:, 1], \"k.\", markersize=2)\n",
    "    ax.set_title(\"KMeans clustering of PCA data\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    return ax\n",
    "\n",
    "\n",
    "# + jupyter={\"outputs_hidden\": false}\n",
    "kmeans11 = KMeans(n_clusters=11).fit(trans)\n",
    "plot_kmeans_pca(trans, kmeans11)\n",
    "# -\n",
    "\n",
    "kmeans4 = KMeans(n_clusters=4).fit(trans)\n",
    "plot_kmeans_pca(trans, kmeans4)\n",
    "\n",
    "pca_predict = my_pca.transform([predict_case])\n",
    "kmeans4.predict(pca_predict)\n",
    "\n",
    "last_train = ind_order[-2]\n",
    "last_train, ind_pop[last_train]\n",
    "\n",
    "kmeans4.predict(trans)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
