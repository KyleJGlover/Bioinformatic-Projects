{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BED File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import HTSeq\n",
    "\n",
    "# Read the genomic intervals from the BED file 'LCT.bed' using HTSeq.BED_Reader\n",
    "lct_bed = HTSeq.BED_Reader('LCT.bed')\n",
    "\n",
    "# Create a defaultdict to count the occurrences of different feature types\n",
    "feature_types = defaultdict(int)\n",
    "\n",
    "# Loop through each record (genomic interval) in the 'lct_bed' object\n",
    "for rec in lct_bed:\n",
    "    last_rec = rec  # Store the last record to access it later\n",
    "    # Extract the feature type from the 'name' attribute using regular expression and update the counter\n",
    "    feature_types[re.search('([A-Z]+)', rec.name).group(0)] += 1\n",
    "\n",
    "print(\"Feature types and their occurrences:\")\n",
    "print(feature_types)\n",
    "\n",
    "# Print information about the last record in the BED file\n",
    "print(\"Information about the last record:\")\n",
    "print(\"Last Record:\", last_rec)\n",
    "print(\"Last Record Name:\", last_rec.name)\n",
    "print(\"Type of Last Record:\", type(last_rec))\n",
    "interval = last_rec.iv\n",
    "print(\"Interval of Last Record:\", interval)\n",
    "print(\"Type of Interval:\", type(interval))\n",
    "\n",
    "# Print specific information about the genomic interval of the last record\n",
    "print(\"Chromosome, Start, and End of Interval:\")\n",
    "print(interval.chrom, interval.start, interval.end)\n",
    "print(\"Strand of Interval:\", interval.strand)\n",
    "print(\"Length of Interval:\", interval.length)\n",
    "print(\"Start Position Description:\", interval.start_d)\n",
    "print(\"Start Position as Position Object:\", interval.start_as_pos)\n",
    "print(\"Type of Start Position as Position Object:\", type(interval.start_as_pos))\n",
    "\n",
    "# Analyze exons from the BED file\n",
    "exon_start = None\n",
    "exon_end = None\n",
    "sizes = []\n",
    "for rec in lct_bed:\n",
    "    # Skip records that do not start with 'CCDS' (not exons)\n",
    "    if not rec.name.startswith('CCDS'):\n",
    "        continue\n",
    "    interval = rec.iv\n",
    "    # Update the exon_start and exon_end with the minimum start and maximum end position among exons\n",
    "    exon_start = min(interval.start, exon_start or interval.start)\n",
    "    exon_end = max(interval.end, exon_end or interval.end)\n",
    "    sizes.append(interval.length)\n",
    "\n",
    "sizes.sort()\n",
    "# Print statistics about the exons\n",
    "print(\"Exon Statistics:\")\n",
    "print(\"Number of Exons:\", len(sizes))\n",
    "print(\"Exon Start Position:\", exon_start)\n",
    "print(\"Exon End Position:\", exon_end)\n",
    "print(\"Smallest Exon Length:\", sizes[0])\n",
    "print(\"Largest Exon Length:\", sizes[-1])\n",
    "print(\"Mean Exon Length: %.1f\" % (sum(sizes) / len(sizes)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pysam\n",
    "\n",
    "# Open the BAM file in read mode\n",
    "bam = pysam.AlignmentFile('NA18489.chrom20.ILLUMINA.bwa.YRI.exome.20121211.bam', 'rb')\n",
    "\n",
    "# Extract and print headers from the BAM file\n",
    "headers = bam.header\n",
    "for record_type, records in headers.items():\n",
    "    print (record_type)\n",
    "    for i, record in enumerate(records):\n",
    "        if type(record) == dict:\n",
    "            print('\\t%d' % (i + 1))\n",
    "            for field, value in record.items():\n",
    "                print('\\t\\t%s\\t%s' % (field, value))\n",
    "        else:\n",
    "            print('\\t\\t%s' % record)\n",
    "\n",
    "# Find and print the first mapped read with both 'M' (match) and 'S' (soft clip) in the CIGAR string\n",
    "for rec in bam:\n",
    "    if rec.cigarstring.find('M') > -1 and rec.cigarstring.find('S') > -1 and not rec.is_unmapped and not rec.mate_is_unmapped:\n",
    "        break\n",
    "print(\"First Read Name:\", rec.query_name)\n",
    "print(\"Reference ID:\", rec.reference_id)\n",
    "print(\"Reference Name:\", bam.getrname(rec.reference_id))\n",
    "print(\"Reference Start:\", rec.reference_start)\n",
    "print(\"Reference End:\", rec.reference_end)\n",
    "print(\"CIGAR String:\", rec.cigarstring)\n",
    "print(\"Query Alignment Start:\", rec.query_alignment_start)\n",
    "print(\"Query Alignment End:\", rec.query_alignment_end)\n",
    "print(\"Query Alignment Length:\", rec.query_alignment_length)\n",
    "print(\"Next Reference ID:\", rec.next_reference_id)\n",
    "print(\"Next Reference Start:\", rec.next_reference_start)\n",
    "print(\"Template Length:\", rec.template_length)\n",
    "print(\"Is Paired?:\", rec.is_paired)\n",
    "print(\"Is Proper Pair?:\", rec.is_proper_pair)\n",
    "print(\"Is Unmapped?:\", rec.is_unmapped)\n",
    "print(\"Mapping Quality:\", rec.mapping_quality)\n",
    "print(\"Query Qualities:\", rec.query_qualities)\n",
    "print(\"Query Alignment Qualities:\", rec.query_alignment_qualities)\n",
    "print(\"Query Sequence:\", rec.query_sequence)\n",
    "\n",
    "# Calculate the percentage of mapped calls as a function of the position from the start of the sequencer read\n",
    "counts = [0] * 76\n",
    "for n, rec in enumerate(bam.fetch('20', 0, 10000000)):\n",
    "    for i in range(rec.query_alignment_start, rec.query_alignment_end):\n",
    "        counts[i] += 1\n",
    "freqs = [100 * x / (n + 1) for x in counts]\n",
    "fig, ax = plt.subplots(figsize=(16, 9), dpi=300, tight_layout=True)\n",
    "ax.plot(range(1, 77), freqs)\n",
    "ax.set_xlabel('Read distance', fontsize='xx-large')\n",
    "ax.set_ylabel('PHRED score', fontsize='xx-large')\n",
    "fig.suptitle('Percentage of mapped calls as a function of the position from the start of the sequencer read', fontsize='xx-large')\n",
    "fig.savefig('map_perc.png')\n",
    "\n",
    "# Calculate the distribution of PHRED scores as a function of the position in the read\n",
    "phreds = defaultdict(list)\n",
    "for rec in bam.fetch('20', 0, None):\n",
    "    for i in range(rec.query_alignment_start, rec.query_alignment_end):\n",
    "        phreds[i].append(rec.query_qualities[i])\n",
    "\n",
    "maxs = [max(phreds[i]) for i in range(76)]\n",
    "tops = [np.percentile(phreds[i], 95) for i in range(76)]\n",
    "medians = [np.percentile(phreds[i], 50) for i in range(76)]\n",
    "bottoms = [np.percentile(phreds[i], 5) for i in range(76)]\n",
    "medians_fig = [x - y for x, y in zip(medians, bottoms)]\n",
    "tops_fig = [x - y for x, y in zip(tops, medians)]\n",
    "maxs_fig = [x - y for x, y in zip(maxs, tops)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9), dpi=300, tight_layout=True)\n",
    "ax.stackplot(range(1, 77), (bottoms, medians_fig, tops_fig, maxs_fig))\n",
    "ax.plot(range(1, 77), maxs, 'k-')\n",
    "ax.set_xlabel('Read distance', fontsize='xx-large')\n",
    "ax.set_ylabel('PHRED score', fontsize='xx-large')\n",
    "fig.suptitle('Distribution of PHRED scores as a function of the position in the read', fontsize='xx-large')\n",
    "fig.savefig('phred2.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Open the FASTQ file and parse the records\n",
    "recs = SeqIO.parse(gzip.open('SRR003265.filt.fastq.gz', 'rt', encoding='utf-8'), 'fastq')\n",
    "\n",
    "# Extract and print the first record's ID, description, and sequence along with its letter annotations (quality scores)\n",
    "rec = next(recs)\n",
    "print(\"ID:\", rec.id)\n",
    "print(\"Description:\", rec.description)\n",
    "print(\"Sequence:\", rec.seq)\n",
    "print(\"Letter Annotations (Quality Scores):\", rec.letter_annotations)\n",
    "\n",
    "# Calculate the percentage of each letter in the sequences\n",
    "recs = SeqIO.parse(gzip.open('SRR003265.filt.fastq.gz', 'rt', encoding='utf-8'), 'fastq')\n",
    "cnt = defaultdict(int)\n",
    "for rec in recs:\n",
    "    for letter in rec.seq:\n",
    "        cnt[letter] += 1\n",
    "tot = sum(cnt.values())\n",
    "for letter, cnt in cnt.items():\n",
    "    print('%s: %.2f %d' % (letter, 100 * cnt / tot, cnt))\n",
    "\n",
    "# Calculate the number of 'N' calls as a function of the distance from the start of the sequencer read and plot the results\n",
    "recs = SeqIO.parse(gzip.open('SRR003265.filt.fastq.gz', 'rt', encoding='UTF-8'), 'fastq')\n",
    "n_cnt = defaultdict(int)\n",
    "for rec in recs:\n",
    "    for i, letter in enumerate(rec.seq):\n",
    "        pos = i + 1\n",
    "        if letter == 'N':\n",
    "            n_cnt[pos] += 1\n",
    "seq_len = max(n_cnt.keys())\n",
    "positions = range(1, seq_len + 1)\n",
    "fig, ax = plt.subplots(figsize=(16, 9), tight_layout=True, dpi=300)\n",
    "fig.suptitle('Number of N calls as a function of the distance from the start of the sequencer read', fontsize='xx-large')\n",
    "ax.plot(positions, [n_cnt[x] for x in positions])\n",
    "ax.set_xlim(1, seq_len)\n",
    "ax.set_xlabel('Read distance', fontsize='xx-large')\n",
    "ax.set_ylabel('Number of N Calls', fontsize='xx-large')\n",
    "fig.savefig('n_calls.png')\n",
    "\n",
    "# Calculate the distribution of PHRED scores as a function of the position in the read and plot the results\n",
    "recs = SeqIO.parse(gzip.open('SRR003265.filt.fastq.gz', 'rt', encoding='utf-8'), 'fastq')\n",
    "cnt_qual = defaultdict(int)\n",
    "for rec in recs:\n",
    "    for i, qual in enumerate(rec.letter_annotations['phred_quality']):\n",
    "        if i < 25:\n",
    "            continue\n",
    "        cnt_qual[qual] += 1\n",
    "tot = sum(cnt_qual.values())\n",
    "for qual, cnt in cnt_qual.items():\n",
    "    print('%d: %.2f %d' % (qual, 100. * cnt / tot, cnt))\n",
    "\n",
    "recs = SeqIO.parse(gzip.open('SRR003265.filt.fastq.gz', 'rt', encoding='utf-8'), 'fastq')\n",
    "qual_pos = defaultdict(list)\n",
    "for rec in recs:\n",
    "    for i, qual in enumerate(rec.letter_annotations['phred_quality']):\n",
    "        if i < 25 or qual == 40:\n",
    "            continue\n",
    "        pos = i + 1\n",
    "        qual_pos[pos].append(qual)\n",
    "vps = []\n",
    "poses = list(qual_pos.keys())\n",
    "poses.sort()\n",
    "for pos in poses:\n",
    "    vps.append(qual_pos[pos])\n",
    "fig, ax = plt.subplots(figsize=(16, 9), dpi=300, tight_layout=True)\n",
    "sns.boxplot(data=vps, ax=ax)\n",
    "ax.set_xticklabels([str(x) for x in range(26, max(qual_pos.keys()) + 1)])\n",
    "ax.set_xlabel('Read distance', fontsize='xx-large')\n",
    "ax.set_ylabel('PHRED score', fontsize='xx-large')\n",
    "fig.suptitle('Distribution of PHRED scores as a function of read distance', fontsize='xx-large')\n",
    "fig.savefig('phred.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from cyvcf2 import VCF\n",
    "\n",
    "# Read and process variant level information from the 'snps.vcf' file\n",
    "v = VCF('snps.vcf')\n",
    "rec = next(v)\n",
    "print('Variant Level information')\n",
    "info = rec.INFO\n",
    "for info in rec.INFO:\n",
    "    print(info)\n",
    "\n",
    "print('Sample Level information')\n",
    "for fmt in rec.FORMAT:\n",
    "    print(fmt)\n",
    "\n",
    "# Read and process variant data from the 'genotypes.vcf.gz' file\n",
    "v = VCF('genotypes.vcf.gz')\n",
    "samples = v.samples\n",
    "print(len(samples))  # Order change\n",
    "\n",
    "variant = next(v)\n",
    "print(variant.CHROM, variant.POS, variant.ID, variant.REF, variant.ALT, variant.QUAL, variant.FILTER)\n",
    "print(variant.INFO)\n",
    "print(variant.FORMAT)\n",
    "print(variant.is_snp)\n",
    "\n",
    "# Extract genotype information for the first variant\n",
    "str_alleles = variant.gt_bases[0]\n",
    "alleles = variant.genotypes[0][0:2]\n",
    "is_phased = variant.genotypes[0][2]\n",
    "print(str_alleles, alleles, is_phased)\n",
    "print(variant.format('DP')[0])\n",
    "\n",
    "# Analyze and print the variant types and counts\n",
    "f = VCF('genotypes.vcf.gz')\n",
    "my_type = defaultdict(int)\n",
    "num_alts = defaultdict(int)\n",
    "\n",
    "for variant in f:\n",
    "    my_type[variant.var_type, variant.var_subtype] += 1\n",
    "    if variant.var_type == 'snp':\n",
    "        num_alts[len(variant.ALT)] += 1\n",
    "print(my_type)\n",
    "print(num_alts)\n",
    "\n",
    "# Analyze and plot the distribution of depth (DP) for SNP variants\n",
    "f = VCF('genotypes.vcf.gz')\n",
    "sample_dp = defaultdict(int)\n",
    "for variant in f:\n",
    "    if not variant.is_snp or len(variant.ALT) != 1:\n",
    "        continue\n",
    "    for dp in variant.format('DP'):\n",
    "        sample_dp[dp] += 1\n",
    "\n",
    "dps = list(sample_dp.keys())\n",
    "dps.sort()\n",
    "dp_dist = [sample_dp[x] for x in dps]\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.plot(dp_dist[:50], 'r')\n",
    "ax.axvline(dp_dist.index(max(dp_dist)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
